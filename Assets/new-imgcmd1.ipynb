{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff8cf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b9852",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Initialize W&B run (if not already initialized)\n",
    "run = wandb.init(\n",
    "    project=\"first-testing-refactored\",\n",
    "    entity=\"daisyabbott\",\n",
    "    notes=\"A set of small/useless datasets for testing.\",\n",
    "    job_type=\"dataset-upload\"\n",
    ")\n",
    "# Load the dataset artifact\n",
    "artifact = run.use_artifact(\"arcslaboratory/Multirun-testing-1K+/larger-perfect-dataset:v0\")\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# Update the dataset path\n",
    "dataset_path = artifact_dir + \"/data/largedata\"  # Path to the extracted images from the artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d47fd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c0e8e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.progress import CSVLogger\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e6f293",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#validation percent and num of epochs\n",
    "VALID_PCT = 0.05\n",
    "NUM_EPOCHS = 3\n",
    "NUM_REPLICATES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3cb5c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# correct server num (using 4th for now, eventually switch to 3rd (2)and share w chau)\n",
    "torch.cuda.set_device(3) \n",
    "print(\"Running on GPU: \" + str(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe5f15",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# adjusted from initial raycasting file for simpler access\n",
    "from pathlib import Path\n",
    "current_dir = Path.cwd()\n",
    "relative_path = \"artifacts/larger-perfect-dataset:v0/data\"\n",
    "path1 = current_dir / relative_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71651d09",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path1.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401fd479",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "files = get_image_files(path1)\n",
    "use_pretraining = True\n",
    "rgb_instead_of_gray = True \n",
    "rep = 1\n",
    "model_name = \"resnet18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a59fb72",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_prefix = \"classification-\" + model_name\n",
    "file_prefix += '-rgb' if rgb_instead_of_gray else '-gray'\n",
    "file_prefix += '-pretrained' if use_pretraining else '-notpretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0674a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "compared_models = {\n",
    "    \"resnet18\": resnet18,\n",
    "    # \"resnet34\": resnet34\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da8d0b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# I may need to double check the vars in this\n",
    "model_filename = path1 / f\"{file_prefix}-{rep}.pkl\"\n",
    "print(\"Model relative filename :\", model_filename)\n",
    "log_filename = path1 / f\"{file_prefix}-trainlog-{rep}.csv\"\n",
    "print(\"Log relative filename   :\", log_filename)\n",
    "print(\"Log relative filename   :\", log_filename)\n",
    "fig_filename_prefix = path1 / file_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19ae899",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_fig_filename(prefix: str, label: str, ext: str, rep: int) -> str:\n",
    "    fig_filename = f\"{prefix}-{label}-{rep}.{ext}\"\n",
    "    print(label, \"filename :\", fig_filename)\n",
    "    return fig_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d350c5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def filename_to_class(filename: str) -> str:\n",
    "    angle = float(filename.split(\"_\")[1].split(\".\")[0].replace(\"p\", \".\"))\n",
    "    if angle > 0:\n",
    "        return \"left\"\n",
    "    elif angle < 0:\n",
    "        return \"right\"\n",
    "    else:\n",
    "        return \"forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07534b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ImageWithCmdDataset(Dataset):\n",
    "    def __init__(self, filenames):\n",
    "        \"\"\"\n",
    "        Creates objects for class labels, class indices, and filenames.\n",
    "        \n",
    "        :param filenames: (list) a list of filenames that make up the dataset\n",
    "        \"\"\"\n",
    "        self.class_labels = ['left', 'forward', 'right']\n",
    "        self.class_indices = {lbl:i for i, lbl in enumerate(self.class_labels)} # {'left': 0, 'forward': 1, 'right': 2}        \n",
    "        self.all_filenames = filenames\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Gives length of dataset.\n",
    "        \n",
    "        :return: (int) the number of filenames in the dataset\n",
    "        \"\"\"\n",
    "        return len(self.all_filenames)\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Gets the filename associated with the given index, opens the image at\n",
    "        that index, then uses the image's filename to get information associated\n",
    "        with the image such as its label and the label of the previous image.\n",
    "        \n",
    "        :param index: (int) number that represents the location of the desired data\n",
    "        :return: (tuple) tuple of all the information associated with the desired data\n",
    "        \"\"\"\n",
    "        # The filename of the image given a specific index\n",
    "        img_filename = self.all_filenames[index]            \n",
    "        \n",
    "        # Opens image file and ensures dimension of channels included\n",
    "        img = Image.open(img_filename).convert('RGB')\n",
    "        # Resizes the image\n",
    "        img = img.resize((224, 224))\n",
    "        # Converts the image to tensor and \n",
    "        img = torch.Tensor(np.array(img)/255)\n",
    "        # changes the order of the dimensions\n",
    "        img = img.permute(2,0,1)\n",
    "        \n",
    "        # Getting the current image's label\n",
    "        label_name = filename_to_class(img_filename)\n",
    "        label = self.class_indices[label_name]\n",
    "        \n",
    "        # Getting the previous image's label\n",
    "        # The default is 'forward'\n",
    "        cmd_name = 'forward'\n",
    "        \n",
    "        # If the index is not 0, the cmd is determined by the previous img_filename\n",
    "        if index != 0:\n",
    "            prev_img_filename = self.all_filenames[index-1]\n",
    "            cmd_name = filename_to_class(prev_img_filename)            \n",
    "        cmd = self.class_indices[cmd_name]\n",
    "        \n",
    "        # Data and the label associated with that data\n",
    "        return (img, cmd), label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5654b00",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dls = ImageDataLoaders.from_name_func(path1, files, filename_to_class, valid_pct = VALID_PCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8375a8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#plt.savefig(get_fig_filename(\"batch\", \"pdf\", rep, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e261192",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class cmd_model(nn.Module):\n",
    "    def __init__(self, arch: str, pretrained: bool):\n",
    "        super(cmd_model, self).__init__()\n",
    "        self.cnn = arch(pretrained=pretrained)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.cnn.fc.out_features + 1, 512)\n",
    "        self.r1 = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        print(data)\n",
    "        img, cmd = data\n",
    "        x1 = self.cnn(img)\n",
    "        x2 = cmd.unsqueeze(1)\n",
    "        \n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.r1(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0962d06a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_dataloaders(dataset_name: str, prefix: str) -> DataLoaders:\n",
    "\n",
    "    path = path1\n",
    "    files = get_image_files(path1)\n",
    "    \n",
    "    # Get size of dataset and corresponding list of indices\n",
    "    dataset_size = len(files)\n",
    "    dataset_indices = list(range(dataset_size))\n",
    "    \n",
    "    # Shuffle the indices\n",
    "    np.random.shuffle(dataset_indices)\n",
    "\n",
    "    # Get the index for where we want to split the data\n",
    "    val_split_index = int(np.floor(VALID_PCT * dataset_size))\n",
    "    \n",
    "    # Split the list of indices into training and validation indices\n",
    "    train_idx, val_idx = dataset_indices[val_split_index:], dataset_indices[:val_split_index]\n",
    "    \n",
    "    # Get the list of filenames for the training and validation sets\n",
    "    train_filenames = [files[i] for i in train_idx]\n",
    "    val_filenames = [files[i] for i in val_idx]\n",
    "    \n",
    "    # Create training and validation datasets\n",
    "    train_data = ImageWithCmdDataset(train_filenames)\n",
    "#     train_data.__get_item__(10)\n",
    "    val_data = ImageWithCmdDataset(val_filenames)\n",
    "    \n",
    "    # Get DataLoader\n",
    "    dls = DataLoaders.from_dsets(train_data, val_data)\n",
    "    dls = dls.cuda()\n",
    "\n",
    "    #dls.show_batch()  # type: ignore\n",
    "    plt.savefig(get_fig_filename(prefix, \"batch\", \"pdf\", 0))\n",
    "\n",
    "    return dls  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b5f906",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(\n",
    "    dls: DataLoaders,\n",
    "    model_arch: str,\n",
    "    pretrained: bool,\n",
    "    logname: Path,\n",
    "    modelname: Path,\n",
    "    prefix: str,\n",
    "    rep: int,\n",
    "):\n",
    "    arch = compared_models[model_arch]\n",
    "    net = cmd_model(arch, pretrained=pretrained)\n",
    "    \n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        net,\n",
    "        loss_func=CrossEntropyLossFlat(),\n",
    "        metrics=accuracy,\n",
    "        cbs=CSVLogger(fname=logname),\n",
    "    )\n",
    "\n",
    "    if pretrained:\n",
    "        learn.fine_tune(NUM_EPOCHS)\n",
    "    else:\n",
    "        learn.fit_one_cycle(NUM_EPOCHS)\n",
    "\n",
    "    # Save trained model\n",
    "    torch.save(net.state_dict(), modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c05010",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#learn = cnn_learner(dls, compared_models[model_name], metrics=accuracy, pretrained=use_pretraining, cbs=CSVLogger(fname=log_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a47209",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# learn.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d47f8d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#if use_pretraining:\n",
    "    #learn.fine_tune(NUM_EPOCHS)\n",
    "#else:\n",
    "    #learn.fit_one_cycle(NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33623827",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    arg_parser = ArgumentParser(\"Train cmd classification networks.\")\n",
    "    arg_parser.add_argument(\n",
    "        \"model_arch\", help=\"Model architecture (see code for options)\"\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"dataset_name\", help=\"Name of dataset to use (corrected-wander-full)\"\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"--pretrained\", action=\"store_true\", help=\"Use pretrained model\"\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    dls = prepare_dataloaders(dataset_path, fig_filename_prefix)\n",
    "    \n",
    "    # Train NUM_REPLICATES separate instances of this model and dataset\n",
    "    for rep in range(NUM_REPLICATES):\n",
    "         train_model(\n",
    "            dls,\n",
    "            args.model_arch,\n",
    "            args.pretrained,\n",
    "            log_filename,\n",
    "            model_filename,\n",
    "            fig_filename_prefix,\n",
    "            rep,\n",
    "        )\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f57ad5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
